name: Run Crawler Every 5 Minutes

on:
  schedule:
    - cron: "*/5 * * * *" # 每五分鐘執行一次

jobs:
  run-crawler:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10" # 指定Python版本

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt  # 假设依赖在此文件中
      - name: Inject prod env settings with database public host
        uses: cschleiden/replace-tokens@v1
        with:
          tokenPrefix: "<"
          tokenSuffix: ">"
          files: '["**/apiadmin/.env"]'
        env:
          SECRET_KEY: ${{ secrets.SECRET_KEY }}
          DEBUG: ${{ secrets.DEBUG }}
          DEFAULT_DATABASE_NAME: ${{ secrets.DEFAULT_DATABASE_NAME }}
          DEFAULT_DATABASE_USER: ${{ secrets.DEFAULT_DATABASE_USER }}
          DEFAULT_DATABASE_PASSWORD: ${{ secrets.DEFAULT_DATABASE_PASSWORD }}
          DEFAULT_DATABASE_HOST: ${{ secrets.DEFAULT_DATABASE_HOST }}
          DEFAULT_DATABASE_PORT: ${{ secrets.DEFAULT_DATABASE_PORT }}
          DEFAULT_DATABASE_URL: ${{ secrets.DEFAULT_DATABASE_URL }}
          DEFAULT_DATABASE_CONN_MAX_AGE: ${{ secrets.DEFAULT_DATABASE_CONN_MAX_AGE }}

      - name: Run crawler script
        run: |
          python adminconfig/utils/crawler.py
